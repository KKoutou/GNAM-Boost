{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ca7c5f-102d-4dfc-b3e5-58b13f222a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 Environment\n",
    "!pip -q install numpy pandas scikit-learn xgboost==2.0.3 torch matplotlib pyyaml scipy joblib pyarrow\n",
    "\n",
    "import os, math, json, gc, random, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch, joblib\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    SEED: int = 42\n",
    "    CSV_PATH: str = r\"C:\\Users\\Nicee\\Desktop\\kenkyu\\INFLUD20-26-06-2025.csv\"\n",
    "    OUT_DIR: str = r\"C:\\Users\\Nicee\\Desktop\\kenkyu\\gnamboost_outputs\"\n",
    "    ROW_LIMIT: int | None = None\n",
    "\n",
    "CFG = Config()\n",
    "\n",
    "def seed_everything(seed: int):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(CFG.SEED)\n",
    "\n",
    "OUT_DIR = Path(CFG.OUT_DIR)\n",
    "FIG_DIR = OUT_DIR / \"figs\"\n",
    "INT_DIR = OUT_DIR / \"interim\"\n",
    "for p in [FIG_DIR, INT_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_PATH = CFG.CSV_PATH\n",
    "row_limit = CFG.ROW_LIMIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f5348f-3f75-4424-8fda-264cd880a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 Read\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "SYMPT  = [\"FEBRE\",\"TOSSE\",\"GARGANTA\",\"DISPNEIA\",\"DESC_RESP\",\"DIARREIA\",\"VOMITO\",\"DOR_ABD\",\"FADIGA\",\"PERD_OLFT\",\"PERD_PALA\",\"OUTRO_SIN\"]\n",
    "COMORB = [\"CARDIOPATI\",\"HEMATOLOGI\",\"HEPATICA\",\"ASMA\",\"DIABETES\",\"NEUROLOGIC\",\"PNEUMOPATI\",\"IMUNODEPRE\",\"RENAL\",\"OBESIDADE\",\"TABAG\"]\n",
    "EXTRA_KEYS = [\"CS_ESCOL_N\",\"CO_UNI_NOT\",\"SEM_NOT\",\"DT_SIN_PRI\",\"DT_NASC\",\"CO_MUN_RES\",\"CO_MU_INTE\"]\n",
    "\n",
    "USE_COLS = [\"DT_INTERNA\",\"EVOLUCAO\",\"CLASSI_FIN\",\"PCR_SARS2\",\"HOSPITAL\",\"NU_IDADE_N\",\"CS_SEXO\",\"CS_RACA\",\"SG_UF_NOT\",\"SG_UF_RES\"] + SYMPT + COMORB + EXTRA_KEYS\n",
    "\n",
    "peek = pd.read_csv(CSV_PATH, sep=';', nrows=5, low_memory=False)\n",
    "usecols = [c for c in USE_COLS if c in peek.columns]\n",
    "df = pd.read_csv(CSV_PATH, sep=';', usecols=usecols, low_memory=False, nrows=row_limit)\n",
    "\n",
    "df[\"UF\"] = np.where(df.get(\"SG_UF_RES\").notna() if \"SG_UF_RES\" in df.columns else False,\n",
    "                    df.get(\"SG_UF_RES\"), df.get(\"SG_UF_NOT\"))\n",
    "df[\"DT_INTERNA\"] = pd.to_datetime(df[\"DT_INTERNA\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c351e20-21f0-40a3-9b28-8c1a81e88436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 Build Overload\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure_epi_week(df0):\n",
    "    df = df0.copy()\n",
    "    if \"SEM_NOT\" in df.columns:\n",
    "        df[\"EPI_WEEK\"] = pd.to_numeric(df[\"SEM_NOT\"], errors=\"coerce\")\n",
    "    elif \"DT_SIN_PRI\" in df.columns:\n",
    "        tmp = pd.to_datetime(df[\"DT_SIN_PRI\"], errors=\"coerce\", dayfirst=True)\n",
    "        df[\"EPI_WEEK\"] = tmp.dt.isocalendar().week.astype(\"Int64\")\n",
    "    else:\n",
    "        df[\"EPI_WEEK\"] = df[\"DT_INTERNA\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "def build_overload(df0):\n",
    "    df = ensure_epi_week(df0)\n",
    "    key = [\"CO_UNI_NOT\",\"EPI_WEEK\"] if set([\"CO_UNI_NOT\",\"EPI_WEEK\"]).issubset(df.columns) else [\"UF\",\"EPI_WEEK\"]\n",
    "    g = df.groupby(key).size().reset_index(name=\"Times\").sort_values(key)\n",
    "    g[\"baseline\"] = g.groupby(key[0])[\"Times\"].transform(lambda s: s.rolling(8, min_periods=3).median().shift(1))\n",
    "    g[\"Overload\"] = (g[\"Times\"] / g[\"baseline\"].replace(0, np.nan)).clip(0.2, 5.0).fillna(1.0)\n",
    "    df = df.merge(g[key + [\"Overload\"]], on=key, how=\"left\")\n",
    "    df[\"Overload\"] = df[\"Overload\"].fillna(1.0)\n",
    "    return df\n",
    "\n",
    "df = build_overload(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4f559f0-07fc-42da-9828-9f522bb447d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N: 307075 | mortality rate: 0.3451\n"
     ]
    }
   ],
   "source": [
    "# Cell 4 Cohort Filters\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "df = df.copy()\n",
    "start, end = pd.Timestamp(\"2020-02-25\"), pd.Timestamp(\"2020-09-21\")\n",
    "df = df[(df[\"DT_INTERNA\"] >= start) & (df[\"DT_INTERNA\"] <= end)]\n",
    "if \"PCR_SARS2\" in df.columns: df = df[df[\"PCR_SARS2\"] == 1]\n",
    "if \"HOSPITAL\" in df.columns: df = df[df[\"HOSPITAL\"] == 1]\n",
    "df = df[df[\"EVOLUCAO\"].isin([1,2])]\n",
    "df[\"NU_IDADE_N\"] = pd.to_numeric(df[\"NU_IDADE_N\"], errors=\"coerce\")\n",
    "df = df[(df[\"NU_IDADE_N\"] >= 0) & (df[\"NU_IDADE_N\"] <= 110)]\n",
    "y = (df[\"EVOLUCAO\"] == 2).astype(int).values\n",
    "\n",
    "print(\"N:\", len(df), \"| mortality rate:\", y.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f588a1-7d0c-4a17-b081-0a6aea8c7708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 Alias & Context Features (leakage-safe)\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "df = df.copy()\n",
    "if \"SEM_NOT\" in df.columns:\n",
    "    df[\"EPI_WEEK\"] = pd.to_numeric(df[\"SEM_NOT\"], errors=\"coerce\")\n",
    "else:\n",
    "    df[\"EPI_WEEK\"] = df[\"DT_INTERNA\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "\n",
    "df[\"_y\"] = (df[\"EVOLUCAO\"] == 2).astype(int)\n",
    "\n",
    "def roll_feats(tbl, key_name):\n",
    "    g = (tbl.groupby([key_name, \"EPI_WEEK\"])\n",
    "           .agg(adm=(\"_y\", \"size\"), death=(\"_y\", \"sum\"))\n",
    "           .reset_index()\n",
    "           .sort_values([key_name, \"EPI_WEEK\"]))\n",
    "    g[\"adm_4w\"]   = g.groupby(key_name)[\"adm\"].transform(lambda s: s.rolling(4, min_periods=1).sum().shift(1))\n",
    "    g[\"death_4w\"] = g.groupby(key_name)[\"death\"].transform(lambda s: s.rolling(4, min_periods=1).sum().shift(1))\n",
    "    g[\"cfr_4w\"]   = (g[\"death_4w\"] / g[\"adm_4w\"].replace(0, np.nan)).fillna(0.0).clip(0, 0.6)\n",
    "    g[\"adm_4w\"]   = g[\"adm_4w\"].fillna(0.0).clip(0, 500)\n",
    "    return g[[key_name, \"EPI_WEEK\", \"cfr_4w\", \"adm_4w\"]]\n",
    "\n",
    "has_hosp = (\"CO_UNI_NOT\" in df.columns) and df[\"CO_UNI_NOT\"].notna().any()\n",
    "if has_hosp:\n",
    "    g_h = roll_feats(df, \"CO_UNI_NOT\").rename(columns={\"cfr_4w\": \"HOSP_CFR_4w\", \"adm_4w\": \"HOSP_ADM_4w\"})\n",
    "    df = df.merge(g_h, on=[\"CO_UNI_NOT\", \"EPI_WEEK\"], how=\"left\")\n",
    "\n",
    "g_s = roll_feats(df, \"UF\").rename(columns={\"cfr_4w\": \"UF_CFR_4w\", \"adm_4w\": \"UF_ADM_4w\"})\n",
    "df = df.merge(g_s, on=[\"UF\", \"EPI_WEEK\"], how=\"left\")\n",
    "\n",
    "def _safe_series(df_, col, default=np.nan):\n",
    "    return df_[col] if col in df_.columns else pd.Series(default, index=df_.index)\n",
    "\n",
    "h_cfr = _safe_series(df, \"HOSP_CFR_4w\", np.nan)\n",
    "u_cfr = _safe_series(df, \"UF_CFR_4w\", np.nan)\n",
    "df[\"CTX_CFR_4w\"] = h_cfr.combine_first(u_cfr).fillna(0.0).clip(0, 0.6)\n",
    "\n",
    "h_adm = _safe_series(df, \"HOSP_ADM_4w\", np.nan)\n",
    "u_adm = _safe_series(df, \"UF_ADM_4w\", np.nan)\n",
    "df[\"CTX_ADM_4w\"] = h_adm.combine_first(u_adm).fillna(0.0).clip(0, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce5daab0-3f40-4c5f-8761-0a3f8b242aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt X before split: (307075, 32)  | y rate: 0.3451274118700643\n"
     ]
    }
   ],
   "source": [
    "# Cell 6 Assemble Feature Matrix\n",
    "SYMPT  = [\"FEBRE\",\"TOSSE\",\"GARGANTA\",\"DISPNEIA\",\"DESC_RESP\",\"DIARREIA\",\"VOMITO\",\"DOR_ABD\",\"FADIGA\",\"PERD_OLFT\",\"PERD_PALA\",\"OUTRO_SIN\"]\n",
    "COMORB = [\"CARDIOPATI\",\"HEMATOLOGI\",\"HEPATICA\",\"ASMA\",\"DIABETES\",\"NEUROLOGIC\",\"PNEUMOPATI\",\"IMUNODEPRE\",\"RENAL\",\"OBESIDADE\",\"TABAG\"]\n",
    "BIN_EXTRA = [\"PUERPERA\",\"CS_GESTANT\"]\n",
    "\n",
    "NUM_KEEP = [\"NU_IDADE_N\",\"AGE_Y\",\"SATURACAO\",\"OBES_IMC\",\"SYMPT_CT\",\"COMORB_CT\",\"DAYS_ONSET_ADM\",\"EPI_WEEK\",\n",
    "            \"Overload\",\"EDU_ORD\",\"AGE_X_EDU\",\"CTX_CFR_4w\",\"CTX_ADM_4w\"]\n",
    "CAT_KEEP = [\"CS_SEXO\",\"CS_RACA\",\"CS_ESCOL_N\",\"UF\",\"CO_UNI_NOT\"]\n",
    "\n",
    "def _exist(cols, df): return [c for c in cols if c in df.columns]\n",
    "\n",
    "base_cols = _exist([\"NU_IDADE_N\",\"CS_SEXO\",\"UF\",\"CS_RACA\"], df)\n",
    "feature_cols = base_cols + _exist(SYMPT, df) + _exist(COMORB, df) + _exist(BIN_EXTRA, df) + _exist(NUM_KEEP, df) + _exist(CAT_KEEP, df)\n",
    "seen=set(); feature_cols=[c for c in feature_cols if not (c in seen or seen.add(c))]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = (df[\"EVOLUCAO\"] == 2).astype(int).values\n",
    "\n",
    "print(\"Rebuilt X before split:\", X.shape, \" | y rate:\", float(y.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caf121c8-4c2e-427e-9463-3a8cb868bd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set: 196576 val set: 49109 test set: 61390\n",
      "mortality rate: 0.3468 0.3427 0.3416\n",
      "max SMD(Train vs Test) = 0.006  | (Train vs Valid) = 0.007\n"
     ]
    }
   ],
   "source": [
    "# Cell 7 Manual Stratified Split on 6 Key Features\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "rng = np.random.RandomState(CFG.SEED)\n",
    "dfS = pd.DataFrame(index=X.index)\n",
    "\n",
    "dfS[\"AGE_BIN\"] = pd.qcut(pd.to_numeric(X[\"NU_IDADE_N\"], errors=\"coerce\"), q=4, duplicates=\"drop\").astype(str)\n",
    "state_col = \"UF\"\n",
    "if state_col not in X.columns: raise KeyError(\"UF col not found\")\n",
    "dfS[\"STATE\"] = X[state_col].astype(str).fillna(\"UNK\")\n",
    "\n",
    "comorb_cols = [\"CARDIOPATI\",\"HEMATOLOGI\",\"HEPATICA\",\"ASMA\",\"DIABETES\",\"NEUROLOGIC\",\"PNEUMOPATI\",\"IMUNODEPRE\",\"RENAL\",\"OBESIDADE\",\"TABAG\"]\n",
    "if \"COMORB_CT\" in X.columns:\n",
    "    com_ct = pd.to_numeric(X[\"COMORB_CT\"], errors=\"coerce\")\n",
    "else:\n",
    "    cc = [c for c in comorb_cols if c in X.columns]\n",
    "    B = X[cc].apply(pd.to_numeric, errors=\"coerce\").replace({2:0,9:np.nan})\n",
    "    com_ct = B.sum(axis=1)\n",
    "dfS[\"COMORB_BIN\"] = pd.cut(com_ct, bins=[-1,0,1,100], labels=[\"0\",\"1\",\"2+\"])\n",
    "\n",
    "edu = pd.to_numeric(df.get(\"CS_ESCOL_N\"), errors=\"coerce\") if \"CS_ESCOL_N\" in df.columns else pd.Series(np.nan, index=X.index)\n",
    "dfS[\"EDU_BIN\"] = edu.replace({9:np.nan}).fillna(-1).astype(int).astype(str)\n",
    "\n",
    "eth_col = \"CS_RACA\" if \"CS_RACA\" in X.columns else None\n",
    "dfS[\"ETH\"] = X[eth_col].astype(str).replace({\"9\":\"MISSING\"}).fillna(\"MISSING\") if eth_col else \"NA\"\n",
    "\n",
    "dfS[\"SEX\"] = X[\"CS_SEXO\"].astype(str).replace({\"9\":\"MISSING\"}).fillna(\"MISSING\") if \"CS_SEXO\" in X.columns else \"NA\"\n",
    "\n",
    "dfS[\"STRATA_RAW\"] = dfS[[\"AGE_BIN\",\"STATE\",\"COMORB_BIN\",\"EDU_BIN\",\"ETH\",\"SEX\"]].astype(str).agg(\"|\".join, axis=1)\n",
    "ct = dfS[\"STRATA_RAW\"].value_counts()\n",
    "MIN_PER = 25\n",
    "rare = set(ct[ct < MIN_PER].index)\n",
    "dfS[\"STRATA\"] = np.where(dfS[\"STRATA_RAW\"].isin(rare), \"RARE\", dfS[\"STRATA_RAW\"])\n",
    "\n",
    "def stratified_split(X, y, strata, test_size=0.2, valid_size=0.2, seed=42):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    df_idx = pd.DataFrame({\"idx\": np.arange(len(X)), \"strata\": strata})\n",
    "    test_idx, valid_idx, train_idx = [], [], []\n",
    "    for s, sub in df_idx.groupby(\"strata\"):\n",
    "        ids = sub[\"idx\"].values\n",
    "        rng.shuffle(ids)\n",
    "        n = len(ids)\n",
    "        n_test  = int(round(n * test_size))\n",
    "        n_valid = int(round((n - n_test) * valid_size))\n",
    "        test_idx.extend(ids[:n_test])\n",
    "        valid_idx.extend(ids[n_test:n_test+n_valid])\n",
    "        train_idx.extend(ids[n_test+n_valid:])\n",
    "    return (X.iloc[train_idx], X.iloc[valid_idx], X.iloc[test_idx],\n",
    "            y[train_idx], y[valid_idx], y[test_idx])\n",
    "\n",
    "Xtr, Xva, Xte, ytr, yva, yte = stratified_split(X, y, dfS[\"STRATA\"], test_size=0.20, valid_size=0.20, seed=CFG.SEED)\n",
    "\n",
    "print(\"training set:\", len(Xtr), \"val set:\", len(Xva), \"test set:\", len(Xte))\n",
    "print(\"mortality rate:\", ytr.mean().round(4), yva.mean().round(4), yte.mean().round(4))\n",
    "\n",
    "def smd_num(a,b):\n",
    "    a = pd.to_numeric(pd.Series(a), errors=\"coerce\").dropna().to_numpy()\n",
    "    b = pd.to_numeric(pd.Series(b), errors=\"coerce\").dropna().to_numpy()\n",
    "    if len(a)<2 or len(b)<2: return np.nan\n",
    "    m1,m2=a.mean(),b.mean(); s1,s2=a.std(ddof=1),b.std(ddof=1); sp=np.sqrt((s1**2+s2**2)/2)\n",
    "    return np.nan if sp==0 else (m1-m2)/sp\n",
    "def smd_cat(s1,s2):\n",
    "    v1=pd.Series(s1).astype(str).fillna(\"MISSING\"); v2=pd.Series(s2).astype(str).fillna(\"MISSING\")\n",
    "    levels=set(v1.unique()).union(v2.unique()); worst=0.0\n",
    "    for lev in levels:\n",
    "        p1=(v1==lev).mean(); p2=(v2==lev).mean(); p=(p1+p2)/2; denom=np.sqrt(p*(1-p)) if 0<p<1 else np.nan\n",
    "        smd=abs(p1-p2)/denom if denom and not np.isnan(denom) else 0.0; worst=max(worst,smd)\n",
    "    return worst\n",
    "def max_smd(A,B):\n",
    "    vals=[abs(smd_num(A[\"NU_IDADE_N\"],B[\"NU_IDADE_N\"])), smd_cat(A[state_col],B[state_col])]\n",
    "    if \"CS_SEXO\" in A.columns: vals.append(smd_cat(A[\"CS_SEXO\"],B[\"CS_SEXO\"]))\n",
    "    if \"CS_RACA\" in A.columns: vals.append(smd_cat(A[\"CS_RACA\"],B[\"CS_RACA\"]))\n",
    "    return np.nanmax([v for v in vals if pd.notna(v)])\n",
    "print(\"max SMD(Train vs Test) =\", round(max_smd(Xtr,Xte),3), \" | (Train vs Valid) =\", round(max_smd(Xtr,Xva),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48f88b1-93be-4219-aa8e-b2cfd31f6019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FE] num=10, bin=23, cat=4, total=37\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 Feature Engineering\n",
    "import pandas as pd, numpy as np\n",
    "\n",
    "Xtr, Xva, Xte = Xtr.copy(), Xva.copy(), Xte.copy()\n",
    "SYMPT  = [\"FEBRE\",\"TOSSE\",\"GARGANTA\",\"DISPNEIA\",\"DESC_RESP\",\"DIARREIA\",\"VOMITO\",\"DOR_ABD\",\"FADIGA\",\"PERD_OLFT\",\"PERD_PALA\",\"OUTRO_SIN\"]\n",
    "COMORB = [\"CARDIOPATI\",\"HEMATOLOGI\",\"HEPATICA\",\"ASMA\",\"DIABETES\",\"NEUROLOGIC\",\"PNEUMOPATI\",\"IMUNODEPRE\",\"RENAL\",\"OBESIDADE\",\"TABAG\"]\n",
    "CAT_CAND = [\"CS_SEXO\",\"CS_RACA\",\"CS_ESCOL_N\",\"UF\",\"CO_UNI_NOT\"]\n",
    "NUM_CAND = [\"AGE_Y\",\"NU_IDADE_N\",\"SATURACAO\",\"OBES_IMC\",\"SYMPT_CT\",\"COMORB_CT\",\"DAYS_ONSET_ADM\",\"EPI_WEEK\",\"Overload\",\"EDU_ORD\",\"AGE_X_EDU\",\"CTX_CFR_4w\",\"CTX_ADM_4w\"]\n",
    "BIN_EXTRA = [\"VAX_ANY\",\"VAX_BOOST\",\"PUERPERA\",\"CS_GESTANT\"]\n",
    "\n",
    "def _to_dt(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns: df[c]=pd.to_datetime(df[c], errors=\"coerce\", dayfirst=True)\n",
    "def _yesno(df, cols):\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            s=df[c]; s=s.where(~s.isin([9,\"9\",0,\"0\",\"\",None]), np.nan)\n",
    "            s=s.where(~s.isin([2,\"2\"]), 0); s=s.where(~s.isin([1,\"1\"]), 1)\n",
    "            df[c]=pd.to_numeric(s, errors=\"coerce\")\n",
    "def _exist(cols, df): return [c for c in cols if c in df.columns]\n",
    "def _mk_age(df):\n",
    "    if \"AGE_Y\" not in df.columns:\n",
    "        if \"NU_IDADE_N\" in df.columns:\n",
    "            df[\"AGE_Y\"]=pd.to_numeric(df[\"NU_IDADE_N\"], errors=\"coerce\")\n",
    "def _mk_counts(df):\n",
    "    sc=_exist(SYMPT,df); cc=_exist(COMORB,df)\n",
    "    if sc: df[\"SYMPT_CT\"]=(df[sc]==1).sum(axis=1)\n",
    "    if cc: df[\"COMORB_CT\"]=(df[cc]==1).sum(axis=1)\n",
    "def _mk_onset(df):\n",
    "    if {\"DT_SIN_PRI\",\"DT_INTERNA\"}.issubset(df.columns):\n",
    "        d=(df[\"DT_INTERNA\"]-df[\"DT_SIN_PRI\"]).dt.days; df[\"DAYS_ONSET_ADM\"]=d.clip(-1,60)\n",
    "def _mk_epi(df):\n",
    "    if \"EPI_WEEK\" not in df.columns:\n",
    "        df[\"EPI_WEEK\"]=pd.to_numeric(df.get(\"EPI_WEEK\"), errors=\"coerce\")\n",
    "def _mk_edu(df):\n",
    "    if \"CS_ESCOL_N\" in df.columns:\n",
    "        df[\"EDU_ORD\"]=pd.to_numeric(df[\"CS_ESCOL_N\"], errors=\"coerce\")\n",
    "        if \"AGE_Y\" in df.columns: df[\"AGE_X_EDU\"]=df[\"AGE_Y\"]*df[\"EDU_ORD\"]\n",
    "\n",
    "for d in (Xtr,Xva,Xte):\n",
    "    _to_dt(d, [\"DT_SIN_PRI\",\"DT_INTERNA\",\"DT_NASC\"])\n",
    "    for c in [\"SATURACAO\",\"OBES_IMC\",\"NU_IDADE_N\",\"Overload\",\"CTX_CFR_4w\",\"CTX_ADM_4w\"]:\n",
    "        if c in d.columns: d[c]=pd.to_numeric(d[c], errors=\"coerce\")\n",
    "for d in (Xtr,Xva,Xte):\n",
    "    _yesno(d, SYMPT+COMORB+[\"PUERPERA\",\"CS_GESTANT\"])\n",
    "    _mk_age(d); _mk_counts(d); _mk_onset(d); _mk_epi(d); _mk_edu(d)\n",
    "\n",
    "num_cols = _exist(NUM_CAND, Xtr)\n",
    "bin_cols = _exist(SYMPT+COMORB+BIN_EXTRA, Xtr)\n",
    "cat_cols = _exist(CAT_CAND, Xtr)\n",
    "cat_cols = [c for c in cat_cols if Xtr[c].nunique(dropna=True) <= 80]\n",
    "\n",
    "feature_cols = list(dict.fromkeys(num_cols + bin_cols + cat_cols)) \n",
    "print(f\"[FE] num={len(num_cols)}, bin={len(bin_cols)}, cat={len(cat_cols)}, total={len(feature_cols)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "573f8ece-b414-4f06-a5d5-7baa75019fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9 Preprocessing (Imputation, Scaling, OHE)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "num_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\", add_indicator=True)), (\"scaler\", StandardScaler())])\n",
    "bin_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\"))])\n",
    "\n",
    "try:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False, min_frequency=10)\n",
    "except TypeError:\n",
    "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "cat_pipe = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", ohe)])\n",
    "\n",
    "preproc = ColumnTransformer([\n",
    "    (\"num\", num_pipe, num_cols),\n",
    "    (\"bin\", bin_pipe, bin_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols),\n",
    "], remainder=\"drop\")\n",
    "\n",
    "Xtr_t = preproc.fit_transform(Xtr[feature_cols])\n",
    "Xva_t = preproc.transform(Xva[feature_cols])\n",
    "Xte_t = preproc.transform(Xte[feature_cols])\n",
    "\n",
    "try:\n",
    "    cat_names = list(preproc.named_transformers_[\"cat\"].named_steps[\"ohe\"].get_feature_names_out(cat_cols))\n",
    "except Exception:\n",
    "    cat_names = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8ebd554-0df0-45f5-bd81-51e64eb4554c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train coverage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>non_null_rate</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>mean_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDU_ORD</td>\n",
       "      <td>0.72049</td>\n",
       "      <td>7</td>\n",
       "      <td>5.682301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE_X_EDU</td>\n",
       "      <td>0.72049</td>\n",
       "      <td>325</td>\n",
       "      <td>335.722285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overload</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>858</td>\n",
       "      <td>1.684532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SYMPT_CT</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>13</td>\n",
       "      <td>3.570970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMORB_CT</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.876897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CTX_CFR_4w</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>747</td>\n",
       "      <td>0.343252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTX_ADM_4w</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>278</td>\n",
       "      <td>477.566366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPI_WEEK</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>53</td>\n",
       "      <td>26.446407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  non_null_rate  n_unique   mean_like\n",
       "1     EDU_ORD        0.72049         7    5.682301\n",
       "2   AGE_X_EDU        0.72049       325  335.722285\n",
       "0    Overload        1.00000       858    1.684532\n",
       "3    SYMPT_CT        1.00000        13    3.570970\n",
       "4   COMORB_CT        1.00000        11    0.876897\n",
       "5  CTX_CFR_4w        1.00000       747    0.343252\n",
       "6  CTX_ADM_4w        1.00000       278  477.566366\n",
       "7    EPI_WEEK        1.00000        53   26.446407"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid coverage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>non_null_rate</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>mean_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDU_ORD</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>7</td>\n",
       "      <td>5.666090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE_X_EDU</td>\n",
       "      <td>0.717404</td>\n",
       "      <td>311</td>\n",
       "      <td>334.476654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overload</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>733</td>\n",
       "      <td>1.682816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SYMPT_CT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>3.570893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMORB_CT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.877660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CTX_CFR_4w</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>696</td>\n",
       "      <td>0.343145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTX_ADM_4w</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>263</td>\n",
       "      <td>477.924657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPI_WEEK</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>26.462461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  non_null_rate  n_unique   mean_like\n",
       "1     EDU_ORD       0.717404         7    5.666090\n",
       "2   AGE_X_EDU       0.717404       311  334.476654\n",
       "0    Overload       1.000000       733    1.682816\n",
       "3    SYMPT_CT       1.000000        13    3.570893\n",
       "4   COMORB_CT       1.000000        11    0.877660\n",
       "5  CTX_CFR_4w       1.000000       696    0.343145\n",
       "6  CTX_ADM_4w       1.000000       263  477.924657\n",
       "7    EPI_WEEK       1.000000        52   26.462461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  coverage:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>non_null_rate</th>\n",
       "      <th>n_unique</th>\n",
       "      <th>mean_like</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDU_ORD</td>\n",
       "      <td>0.722658</td>\n",
       "      <td>7</td>\n",
       "      <td>5.691056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGE_X_EDU</td>\n",
       "      <td>0.722658</td>\n",
       "      <td>313</td>\n",
       "      <td>336.282887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overload</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>777</td>\n",
       "      <td>1.680717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SYMPT_CT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>13</td>\n",
       "      <td>3.559912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMORB_CT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.877211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CTX_CFR_4w</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>709</td>\n",
       "      <td>0.343058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CTX_ADM_4w</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>262</td>\n",
       "      <td>477.162437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EPI_WEEK</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>26.461443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  non_null_rate  n_unique   mean_like\n",
       "1     EDU_ORD       0.722658         7    5.691056\n",
       "2   AGE_X_EDU       0.722658       313  336.282887\n",
       "0    Overload       1.000000       777    1.680717\n",
       "3    SYMPT_CT       1.000000        13    3.559912\n",
       "4   COMORB_CT       1.000000        11    0.877211\n",
       "5  CTX_CFR_4w       1.000000       709    0.343058\n",
       "6  CTX_ADM_4w       1.000000       262  477.162437\n",
       "7    EPI_WEEK       1.000000        53   26.461443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 10 Quick Check\n",
    "def coverage(df_in, cols):\n",
    "    rows=[]\n",
    "    for c in cols:\n",
    "        if c in df_in.columns:\n",
    "            s=df_in[c]; nn=s.notna().mean(); uniq=s.nunique(dropna=True)\n",
    "            rows.append([c, nn, uniq, np.nan if s.dropna().empty else float(np.nanmean(pd.to_numeric(s, errors=\"coerce\")))])\n",
    "        else:\n",
    "            rows.append([c, 0.0, 0, np.nan])\n",
    "    return pd.DataFrame(rows, columns=[\"feature\",\"non_null_rate\",\"n_unique\",\"mean_like\"]).sort_values(\"non_null_rate\")\n",
    "\n",
    "key_cols = [\"Overload\",\"EDU_ORD\",\"AGE_X_EDU\",\"SYMPT_CT\",\"COMORB_CT\",\"CTX_CFR_4w\",\"CTX_ADM_4w\",\"EPI_WEEK\"]\n",
    "print(\"Train coverage:\"); display(coverage(Xtr, key_cols))\n",
    "print(\"Valid coverage:\"); display(coverage(Xva, key_cols))\n",
    "print(\"Test  coverage:\"); display(coverage(Xte, key_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75688a2-0eb0-43ed-b060-2278c0f84418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts saved to: C:\\Users\\Nicee\\Desktop\\kenkyu\\gnamboost_outputs\\interim\n"
     ]
    }
   ],
   "source": [
    "# Persist Artifacts\n",
    "meta = {\n",
    "    \"feature_cols\": feature_cols,\n",
    "    \"num_cols\": num_cols,\n",
    "    \"bin_cols\": bin_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"cat_names\": cat_names,\n",
    "    \"seed\": CFG.SEED,\n",
    "}\n",
    "\n",
    "joblib.dump(Xtr, INT_DIR/\"Xtr.pkl\"); joblib.dump(Xva, INT_DIR/\"Xva.pkl\"); joblib.dump(Xte, INT_DIR/\"Xte.pkl\")\n",
    "joblib.dump(ytr, INT_DIR/\"ytr.npy\"); joblib.dump(yva, INT_DIR/\"yva.npy\"); joblib.dump(yte, INT_DIR/\"yte.npy\")\n",
    "\n",
    "joblib.dump(Xtr_t, INT_DIR/\"Xtr_t.npy\"); joblib.dump(Xva_t, INT_DIR/\"Xva_t.npy\"); joblib.dump(Xte_t, INT_DIR/\"Xte_t.npy\")\n",
    "\n",
    "joblib.dump(preproc, INT_DIR/\"preproc.joblib\")\n",
    "with open(INT_DIR/\"meta.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(meta, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "df_min = df.copy()\n",
    "df_min.to_parquet(INT_DIR/\"df_filtered.parquet\", index=False)\n",
    "print(\"Artifacts saved to:\", INT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
